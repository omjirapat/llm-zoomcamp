{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework: LLM Orchestration and Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Running Mage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mage-ai                                  0.9.72\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! docker exec -it eea4e16ee4d9 sh -c \"pip list | grep mage-ai\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Reading the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "import requests\n",
    "import docx\n",
    "\n",
    "\n",
    "if 'data_loader' not in globals():\n",
    "    from mage_ai.data_preparation.decorators import data_loader\n",
    "if 'test' not in globals():\n",
    "    from mage_ai.data_preparation.decorators import test\n",
    "\n",
    "\n",
    "@data_loader\n",
    "def load_data(*args, **kwargs):\n",
    "\n",
    "\n",
    "    def clean_line(line):\n",
    "        line = line.strip()\n",
    "        line = line.strip('\\uFEFF')\n",
    "        return line\n",
    "\n",
    "    def read_faq(file_id):\n",
    "        url = f'https://docs.google.com/document/d/{file_id}/export?format=docx'\n",
    "        \n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        with io.BytesIO(response.content) as f_in:\n",
    "            doc = docx.Document(f_in)\n",
    "\n",
    "        questions = []\n",
    "\n",
    "        question_heading_style = 'heading 2'\n",
    "        section_heading_style = 'heading 1'\n",
    "        \n",
    "        heading_id = ''\n",
    "        section_title = ''\n",
    "        question_title = ''\n",
    "        answer_text_so_far = ''\n",
    "\n",
    "        for p in doc.paragraphs:\n",
    "            style = p.style.name.lower()\n",
    "            p_text = clean_line(p.text)\n",
    "        \n",
    "            if len(p_text) == 0:\n",
    "                continue\n",
    "        \n",
    "            if style == section_heading_style:\n",
    "                section_title = p_text\n",
    "                continue\n",
    "        \n",
    "            if style == question_heading_style:\n",
    "                answer_text_so_far = answer_text_so_far.strip()\n",
    "                if answer_text_so_far != '' and section_title != '' and question_title != '':\n",
    "                    questions.append({\n",
    "                        'text': answer_text_so_far,\n",
    "                        'section': section_title,\n",
    "                        'question': question_title,\n",
    "                    })\n",
    "                    answer_text_so_far = ''\n",
    "        \n",
    "                question_title = p_text\n",
    "                continue\n",
    "            \n",
    "            answer_text_so_far += '\\n' + p_text\n",
    "        \n",
    "        answer_text_so_far = answer_text_so_far.strip()\n",
    "        if answer_text_so_far != '' and section_title != '' and question_title != '':\n",
    "            questions.append({\n",
    "                'text': answer_text_so_far,\n",
    "                'section': section_title,\n",
    "                'question': question_title,\n",
    "            })\n",
    "\n",
    "        return questions\n",
    "\n",
    "    faq_documents = {\n",
    "        'llm-zoomcamp': '1qZjwHkvP0lXHiE4zdbWyUXSVfmVGzougDD6N37bat3E',\n",
    "    }\n",
    "\n",
    "    documents = []\n",
    "\n",
    "    for course, file_id in faq_documents.items():\n",
    "        course_documents = read_faq(file_id)\n",
    "        documents.append({'course': course, 'documents': course_documents})\n",
    "\n",
    "    print(len(documents))\n",
    "\n",
    "    return documents\n",
    "\n",
    "\n",
    "@test\n",
    "def test_output(output, *args) -> None:\n",
    "    \"\"\"\n",
    "    Template code for testing the output of the block.\n",
    "    \"\"\"\n",
    "    assert output is not None, 'The output is undefined'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "if 'transformer' not in globals():\n",
    "    from mage_ai.data_preparation.decorators import transformer\n",
    "if 'test' not in globals():\n",
    "    from mage_ai.data_preparation.decorators import test\n",
    "\n",
    "\n",
    "@transformer\n",
    "def transform(data, *args, **kwargs):\n",
    "\n",
    "    def generate_document_id(doc):\n",
    "        combined = f\"{doc['course']}-{doc['question']}-{doc['text'][:10]}\"\n",
    "        hash_object = hashlib.md5(combined.encode())\n",
    "        hash_hex = hash_object.hexdigest()\n",
    "        document_id = hash_hex[:8]\n",
    "        return document_id\n",
    "\n",
    "    documents = []\n",
    "\n",
    "    for doc in data['documents']:\n",
    "        doc['course'] = data['course']\n",
    "        # previously we used just \"id\" for document ID\n",
    "        doc['document_id'] = generate_document_id(doc)\n",
    "        documents.append(doc)\n",
    "        print(doc)\n",
    "\n",
    "    print(len(documents))\n",
    "\n",
    "    return documents\n",
    "\n",
    "\n",
    "@test\n",
    "def test_output(output, *args) -> None:\n",
    "    \"\"\"\n",
    "    Template code for testing the output of the block.\n",
    "    \"\"\"\n",
    "    assert output is not None, 'The output is undefined'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "< class 'dict'>\n",
    "\n",
    "86"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple, Union\n",
    "from datetime import datetime\n",
    "from mage_ai.data_preparation.variable_manager import set_global_variable\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "if 'data_exporter' not in globals():\n",
    "    from mage_ai.data_preparation.decorators import data_exporter\n",
    "\n",
    "\n",
    "@data_exporter\n",
    "def elasticsearch(\n",
    "    documents: List[Dict[str, Union[Dict, List[int], np.ndarray, str]]], *args, **kwargs,\n",
    "):\n",
    "    \"\"\"\n",
    "    Exports document data to an Elasticsearch database.\n",
    "    \"\"\"\n",
    "\n",
    "    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n",
    "    index_name_prefix = kwargs.get('index_name', 'documents')\n",
    "    current_time = datetime.now().strftime(\"%Y%m%d_%M%S\")\n",
    "    index_name = f\"{index_name_prefix}_{current_time}\"\n",
    "    print(\"index name:\", index_name)\n",
    "    set_global_variable('awe_inspiring_vortex', 'index_name', index_name)\n",
    "\n",
    "    number_of_shards = kwargs.get('number_of_shards', 1)\n",
    "    number_of_replicas = kwargs.get('number_of_replicas', 0)\n",
    "    vector_column_name = kwargs.get('vector_column_name', 'embedding')\n",
    "\n",
    "    dimensions = kwargs.get('dimensions')\n",
    "    if dimensions is None and len(documents) > 0:\n",
    "        document = documents[0]\n",
    "        dimensions = len(document.get(vector_column_name) or [])\n",
    "\n",
    "    es_client = Elasticsearch(connection_string)\n",
    "\n",
    "    print(f'Connecting to Elasticsearch at {connection_string}')\n",
    "\n",
    "    index_settings = {\n",
    "        \"settings\": {\n",
    "            \"number_of_shards\": number_of_shards,\n",
    "            \"number_of_replicas\": number_of_replicas\n",
    "        },\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"text\": {\"type\": \"text\"},\n",
    "                \"section\": {\"type\": \"text\"},\n",
    "                \"question\": {\"type\": \"text\"},\n",
    "                \"course\": {\"type\": \"keyword\"},\n",
    "                \"document_id\": {\"type\": \"keyword\"}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if not es_client.indices.exists(index=index_name):\n",
    "        es_client.indices.create(index=index_name)\n",
    "        print('Index created with properties:', index_settings)\n",
    "        print('Embedding dimensions:', dimensions)\n",
    "\n",
    "    print(f'Indexing {len(documents)} documents to Elasticsearch index {index_name}')\n",
    "    for document in documents:\n",
    "        print(f'Indexing document {document[\"document_id\"]}')\n",
    "\n",
    "        es_client.index(index=index_name, document=document)\n",
    "\n",
    "    print(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "index_name: documents_20240818_4321\n",
    "\n",
    "Connecting to Elasticsearch at ...\n",
    "\n",
    "...\n",
    "\n",
    "'document_id': 'a976d6e7'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. Testing the retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Union\n",
    "\n",
    "import numpy as np\n",
    "from elasticsearch import Elasticsearch, exceptions\n",
    "\n",
    "if 'data_loader' not in globals():\n",
    "    from mage_ai.data_preparation.decorators import data_loader\n",
    "if 'test' not in globals():\n",
    "    from mage_ai.data_preparation.decorators import test\n",
    "\n",
    "SAMPLE_QUESTION = \"When is the next cohort?\"\n",
    "\n",
    "\n",
    "@data_loader\n",
    "def search(*args, **kwargs) -> List[Dict]:\n",
    "    connection_string = kwargs.get('connection_string', 'http://localhost:9200')\n",
    "    index_name = kwargs.get('index_name', 'documents_20240818_4321')\n",
    "    top_k = kwargs.get('top_k', 5)\n",
    "\n",
    "    question = ''\n",
    "    if len(args):\n",
    "        question = args[0]\n",
    "    if not question:\n",
    "        question = SAMPLE_QUESTION\n",
    "\n",
    "    query = {\n",
    "        \"bool\": {\n",
    "            \"must\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": question,\n",
    "                    \"fields\": [\"question^3\", \"text\"],\n",
    "                    \"type\": \"best_fields\"\n",
    "                }\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "    es_client = Elasticsearch(connection_string)\n",
    "\n",
    "    try:\n",
    "        response = es_client.search(\n",
    "            index=index_name,\n",
    "            body={\n",
    "                \"size\": top_k,\n",
    "                \"query\": query,\n",
    "            },\n",
    "        )\n",
    "\n",
    "        top_match = response['hits']['hits'][0]['_source']['document_id']\n",
    "        print(top_match)\n",
    "        return top_match\n",
    "    \n",
    "    except exceptions.BadRequestError as e:\n",
    "        print(f\"BadRequestError: {e.info}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "        return []\n",
    "\n",
    "@test\n",
    "def test_output(output, *args) -> None:\n",
    "    \"\"\"\n",
    "    Template code for testing the output of the block.\n",
    "    \"\"\"\n",
    "    assert output is not None, 'The output is undefined'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'bf024675'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6. Reindexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'b6fa77f3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-zoomcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
