{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation and Monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rouge import Rouge\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_url = \"https://github.com/DataTalksClub/llm-zoomcamp/blob/main/04-monitoring/data/results-gpt4o-mini.csv\"\n",
    "\n",
    "url = f'{github_url}?raw=1'\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. Getting the embeddibngs model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"multi-qa-mpnet-base-dot-v1\"\n",
    "embedding_model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_llm = df.iloc[0].answer_llm\n",
    "answer_llm_embedded = embedding_model.encode(answer_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.42244658"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_llm_embedded[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What's the first value of the resulting vector?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer*: -0.42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. Computing the dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity(record):\n",
    "    answer_orig = record['answer_orig']\n",
    "    answer_llm = record['answer_llm']\n",
    "    \n",
    "    v_llm = embedding_model.encode(answer_llm)\n",
    "    v_orig = embedding_model.encode(answer_orig)\n",
    "    \n",
    "    return v_llm.dot(v_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df = df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a86d3b46c6dc43a0958773cfc9c6e10a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluations = []\n",
    "\n",
    "for record in tqdm(dict_df):\n",
    "    sim = compute_similarity(record)\n",
    "    evaluations.append(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    300.000000\n",
       "mean      27.495996\n",
       "std        6.384742\n",
       "min        4.547925\n",
       "25%       24.307845\n",
       "50%       28.336873\n",
       "75%       31.674312\n",
       "max       39.476013\n",
       "Name: cosine, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cosine'] = evaluations\n",
    "df['cosine'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What's the 75% percentile of the score?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer*: 31.67"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3. Computing the cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(v):\n",
    "    norm = np.sqrt((v * v).sum())\n",
    "    v_norm = v / norm\n",
    "    \n",
    "    return v_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db4cecf7cbe94b2cb8af302ab6b6e96d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "norm_eval = []\n",
    "\n",
    "for record in tqdm(dict_df):\n",
    "    v_llm = normalize(embedding_model.encode(record[\"answer_llm\"]))\n",
    "    v_orig = normalize(embedding_model.encode(record[\"answer_orig\"]))\n",
    "\n",
    "    sim = v_llm.dot(v_orig)\n",
    "    norm_eval.append(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    300.000000\n",
       "mean       0.728393\n",
       "std        0.157755\n",
       "min        0.125357\n",
       "25%        0.651273\n",
       "50%        0.763761\n",
       "75%        0.836235\n",
       "max        0.958796\n",
       "Name: norm_cosine, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"norm_cosine\"] = norm_eval\n",
    "df[\"norm_cosine\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What's the 75% cosine in the scores?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer:* 0.83"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4. Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = df.iloc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "answer_llm     Yes, all sessions are recorded, so if you miss...\n",
       "answer_orig    Everything is recorded, so you wonâ€™t miss anyt...\n",
       "document                                                5170565b\n",
       "question                    Are sessions recorded if I miss one?\n",
       "course                                 machine-learning-zoomcamp\n",
       "cosine                                                 32.344711\n",
       "norm_cosine                                             0.777956\n",
       "Name: 10, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_scorer = Rouge()\n",
    "\n",
    "scores = rouge_scorer.get_scores(sentence['answer_llm'], sentence['answer_orig'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'rouge-1': {'r': 0.45454545454545453,\n",
       "   'p': 0.45454545454545453,\n",
       "   'f': 0.45454544954545456},\n",
       "  'rouge-2': {'r': 0.21621621621621623,\n",
       "   'p': 0.21621621621621623,\n",
       "   'f': 0.21621621121621637},\n",
       "  'rouge-l': {'r': 0.3939393939393939,\n",
       "   'p': 0.3939393939393939,\n",
       "   'f': 0.393939388939394}}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What's the F score for rouge-1?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer:* 0.45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5. Average rouge score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35000000000000003"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([0.45, 0.21, 0.39])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer:* 0.35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6. Average rouge score for all the data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7291b4c71f34708b4e584253aa15ba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for rec in tqdm(dict_df):\n",
    "    score = rouge_scorer.get_scores(rec[\"answer_llm\"], rec[\"answer_orig\"])\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_data = []\n",
    "\n",
    "for item in scores:\n",
    "    if isinstance(item, dict):\n",
    "        flattened_entry = {}\n",
    "        for key, sub_dict in item.items():\n",
    "            for sub_key, value in sub_dict.items():\n",
    "                flattened_entry[f\"{key}-{sub_key}\"] = value\n",
    "        flattened_data.append(flattened_entry)\n",
    "    elif isinstance(item, list):\n",
    "        for sub_item in item:\n",
    "            flattened_entry = {}\n",
    "            for key, sub_dict in sub_item.items():\n",
    "                for sub_key, value in sub_dict.items():\n",
    "                    flattened_entry[f\"{key}-{sub_key}\"] = value\n",
    "            flattened_data.append(flattened_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge-1</th>\n",
       "      <th>rouge-2</th>\n",
       "      <th>rouge-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.393939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.028169</td>\n",
       "      <td>0.095238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.093750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.415584</td>\n",
       "      <td>0.177778</td>\n",
       "      <td>0.389610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.216216</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.189189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rouge-1   rouge-2   rouge-l\n",
       "0  0.454545  0.216216  0.393939\n",
       "1  0.095238  0.028169  0.095238\n",
       "2  0.125000  0.055556  0.093750\n",
       "3  0.415584  0.177778  0.389610\n",
       "4  0.216216  0.047059  0.189189"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rouge = pd.DataFrame(flattened_data)\n",
    "df_rouge = df_rouge[[\"rouge-1-f\", \"rouge-2-f\", \"rouge-l-f\"]]\n",
    "df_rouge.rename(columns = {\"rouge-1-f\": \"rouge-1\",\n",
    "                           \"rouge-2-f\": \"rouge-2\",\n",
    "                           \"rouge-l-f\": \"rouge-l\"}, inplace=True)\n",
    "df_rouge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge-1</th>\n",
       "      <th>rouge-2</th>\n",
       "      <th>rouge-l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>301.000000</td>\n",
       "      <td>301.000000</td>\n",
       "      <td>301.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.379095</td>\n",
       "      <td>0.206996</td>\n",
       "      <td>0.353941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.165757</td>\n",
       "      <td>0.153295</td>\n",
       "      <td>0.162709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.098361</td>\n",
       "      <td>0.228571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.379747</td>\n",
       "      <td>0.178771</td>\n",
       "      <td>0.338235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.479042</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.451613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          rouge-1     rouge-2     rouge-l\n",
       "count  301.000000  301.000000  301.000000\n",
       "mean     0.379095    0.206996    0.353941\n",
       "std      0.165757    0.153295    0.162709\n",
       "min      0.000000    0.000000    0.000000\n",
       "25%      0.262295    0.098361    0.228571\n",
       "50%      0.379747    0.178771    0.338235\n",
       "75%      0.479042    0.285714    0.451613\n",
       "max      0.850000    0.739130    0.850000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rouge.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What's the average `rouge_2` across all the records?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer:* 0.20"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
